# -*- coding: utf-8 -*-
"""PR_PROJECT_GROUP_14

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LZrQuzAZ6w_3SW1Vrn6-WUX9K8l3akME
"""

#run the cells in order as no cell is connected to another
#created by group14 of pr team
#first svm gaussian classifier,then k nearest neighbours and then PCA done in svm gaussian classifier
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.colors as colors              
from sklearn.utils import resample
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import scale
from sklearn import svm
from sklearn.svm import SVC
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import confusion_matrix
from sklearn.metrics import plot_confusion_matrix
from sklearn import datasets

from sklearn.metrics import accuracy_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import StandardScaler

x1=np.loadtxt('http://archive.ics.uci.edu/ml/machine-learning-databases/optdigits/optdigits.tra',delimiter=",")#training data
x2=np.loadtxt('http://archive.ics.uci.edu/ml/machine-learning-databases/optdigits/optdigits.tes',delimiter=",")#testing data
print(len(x1))
print(len(x2))

#separating labels from data 
#in optdigits.tra,65th column is class label 
count=0
x_train=[]
y_train=[]
for i in x1:
    x=[]
    for j in i:
        count=count+1
        if count<65:
            x.append(j)
        elif count==65:
            y_train.append(j)
            x_train.append(x)
            count=0
print(len(y_train))

#in optdigits.tes 65th column is label
count=0
x_test=[]
y_test=[]
for i in x2:
    x=[]
    for j in i:
        count=count+1
        if count<65:
            x.append(j)
        elif count==65:
            y_test.append(j)
            x_test.append(x)
            count=0
print(len(x_test))

#findout optimal parameters for gausian SVM
param_grid=[
    {'C' : [0.5,1,10,100,1000],
     'gamma':['scale', 1, 0.1, 0.01, 0.001, 0.001],
     'kernel':['rbf'] },
]
optimal_params= GridSearchCV(
    SVC(),
    param_grid,
    cv=5,
    scoring='accuracy',

)
optimal_params.fit(x_train, y_train)
print(optimal_params.best_params_)

#create a gaussian classifier
clf=svm.SVC(gamma=0.001,C=10)
clf.fit(x_train,y_train)

#plotting confusion matrix
plot_confusion_matrix(clf,
                      x_test,
                      y_test,
                      values_format='d',
                     )

#showing related data of 1stimage 
z=x_test[0]
x11=np.array(z)
x1_new=x11.reshape(8,8)
print(x1_new)
print(len(x1_new))
plt.imshow(x1_new,cmap=plt.cm.gray_r,interpolation="nearest")

#predictions of testing data
y_prediction=[]
for q in x_test:
    x=clf.predict([q])
    y_prediction.append(x[0])
#print(y_prediction[0])
#print(y_test[0])
print('accuracy percentage:',100*accuracy_score(y_test, y_prediction,normalize=True))
print('no of correct predictions:',accuracy_score(y_test, y_prediction,normalize=False))

#creating a k-nearest neighbour classifier
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(x_train, y_train)
#Predict the response for test dataset
y_pred = knn.predict(x_test)
#plot confusion matrix
plot_confusion_matrix(clf,
                      x_test,
                      y_test,
                      values_format='d',
                     )
accuracy_score(y_test, y_pred,normalize=False)

#checking the accuracies for different values of k
for i in range(1,15):
  knn = KNeighborsClassifier(n_neighbors=i)
  knn.fit(x_train, y_train)
  y_pred = knn.predict(x_test)
  c=accuracy_score(y_test, y_pred,normalize=True)
  d=accuracy_score(y_test,  y_pred,normalize=False)
  print(' value of k:',i,'accuracy:',c,'no of correct predictions:',d)

scaler = StandardScaler()# Fit on training set only.
scaler.fit(x_train)# Apply transform to both the training set and the test set.
train_img = scaler.transform(x_train)
test_img = scaler.transform(x_test)

from sklearn.decomposition import PCA# Make an instance of the Model
pca = PCA(.95)

pca.fit(train_img)#training data only

train_img = pca.transform(train_img)
test_img = pca.transform(test_img)

clf1=svm.SVC(gamma=0.001,C=10)
clf1.fit(train_img,y_train)

print(test_img[0])#to see how many features comes under 95% variance

#predictions on testing data
y_img_prediction=[]
for q in test_img:
    x=clf1.predict([q])
    y_img_prediction.append(x[0])

#print(len(y_img_prediction))
#print(y_img_prediction[0])
print('accuracy:',100*accuracy_score(y_test, y_img_prediction,normalize=True))
print('no of correct predictions:',accuracy_score(y_test, y_img_prediction,normalize=False))